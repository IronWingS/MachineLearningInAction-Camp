{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadSimpData():  #一个简单的数据集和标签集\n",
    "    datMat = np.matrix([[1.,2.1],\n",
    "                        [2.,1.1],\n",
    "                        [1.3,1.],\n",
    "                        [1.,1.],\n",
    "                        [2.,1.]])\n",
    "    classLabels = [1.0,1.0,-1.0,-1.0,1.0]\n",
    "    return datMat,classLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stumpClassify(dataMatrix,dimen,threshVal,threshIneq): #分类函数\n",
    "    retArray = np.ones((np.shape(dataMatrix)[0],1))  #初始化标签数组，令其全部为1\n",
    "    if threshIneq == 'It':  #如果包含It\n",
    "        retArray[dataMatrix[:,dimen] <= threshVal] = -1.0 #数据集给定列小于给定值，则令其标签为-1\n",
    "    else:   \n",
    "        retArray[dataMatrix[:,dimen] > threshVal] = -1.0  #其他情况下，数据集给定列大于给定值，令其标签为-1\n",
    "    return retArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildStump(dataArr,classLabels,D):  #创建二叉树\n",
    "    dataMatrix = np.mat(dataArr);labelMat = np.mat(classLabels).T #提取数据集和标签集，并转换为矩阵\n",
    "    m,n = np.shape(dataMatrix)  #数据集行列\n",
    "    numSetps = 10.0  #\n",
    "    bestStump  = {}\n",
    "    bestClasEst = np.mat(np.zeros((m,1)))\n",
    "    minError = np.inf\n",
    "    for i in range(n):\n",
    "        rangeMin = dataMatrix[:,i].min();rangeMax = dataMatrix[:,i].max();\n",
    "        stepSize = (rangeMax - rangeMin)/numSetps\n",
    "        for j in range(-1,int(numSetps) + 1):\n",
    "            for inequal in ['lt','gt']:\n",
    "                threshVal = (rangeMin + float(j) * stepSize)\n",
    "                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)\n",
    "                errArr = np.mat(np.ones((m,1)))\n",
    "                errArr[predictedVals == labelMat] = 0\n",
    "                weightedError = D.T*errArr\n",
    "                #print(\"split: dim %d,thresh %.2f,thresh ineqal: %s,the weighted error is %.3f\" % (i,threshVal,inequal,weightedError))\n",
    "                if weightedError < minError:\n",
    "                    minError = weightedError\n",
    "                    bestClasEst = predictedVals.copy()\n",
    "                    bestStump['dim'] = i\n",
    "                    bestStump['thresh'] = threshVal\n",
    "                    bestStump['ineq'] = inequal\n",
    "    return bestStump,minError,bestClasEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMat,classLabel = loadSimpData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2],\n",
       "        [0.2]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = np.mat(np.ones((5,1))/5);D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'dim': 0, 'thresh': 2.0, 'ineq': 'lt'}, matrix([[0.4]]), array([[1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildStump(dataMat,classLabel,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaBoostTrainDS(dataArr,classLabels,numIt = 40):\n",
    "    weakClassArr = []\n",
    "    m = np.shape(dataArr)[0]\n",
    "    D = np.mat(np.ones((m,1))/m)\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(numIt):\n",
    "        bestStump,error,classEst = buildStump(dataArr,classLabels,D)\n",
    "        #print(\"D:\",D.T)      \n",
    "        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16)))\n",
    "        bestStump['alpha'] = alpha\n",
    "        weakClassArr.append(bestStump)\n",
    "        #print(\"classEst: \",classEst.T)\n",
    "        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst)\n",
    "        D = np.multiply(D,np.exp(expon))\n",
    "        D = D/D.sum()\n",
    "        aggClassEst += alpha * classEst\n",
    "        #print(\"aggClassEst: \",aggClassEst.T)\n",
    "        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T,np.ones((m,1)))\n",
    "        errorRate = aggErrors.sum()/m\n",
    "        print(\"total error: \",errorRate,\"\\n\")\n",
    "        if errorRate == 0.0: break\n",
    "    return weakClassArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: [[0.2 0.2 0.2 0.2 0.2]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[1. 1. 1. 1. 1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n",
      "D: [[0.16666667 0.16666667 0.25       0.25       0.16666667]]\n",
      "classEst:  [[-1. -1. -1. -1. -1.]]\n",
      "aggClassEst:  [[0.20273255 0.20273255 0.20273255 0.20273255 0.20273255]]\n",
      "total error:  0.4 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifierArray = adaBoostTrainDS(dataMat,classLabel,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'dim': 0, 'thresh': 2.0, 'ineq': 'lt', 'alpha': 0.2027325540540821},\n",
       " {'dim': 0, 'thresh': 2.0, 'ineq': 'lt', 'alpha': 1.1102230246251564e-16},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0},\n",
       " {'dim': 0, 'thresh': 0.9, 'ineq': 'lt', 'alpha': 0.0}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaClassify(datToClass,classifierArr):\n",
    "    dataMatrix = np.mat(datToClass)\n",
    "    m = np.shape(dataMatrix)[0]\n",
    "    aggClassEst = np.mat(np.zeros((m,1)))\n",
    "    for i in range(len(classifierArray)):\n",
    "        classEst = stumpClassify(dataMatrix,classifierArr[i]['dim'],\\\n",
    "                                           classifierArr[i]['thresh'],\\\n",
    "                                           classifierArr[i]['ineq'])\n",
    "        aggClassEst += classifierArr[i]['alpha']*classEst\n",
    "        print(aggClassEst)\n",
    "    return np.sign(aggClassEst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n",
      "[[0.20273255]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adaClassify([0,0],classifierArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSet(fileName):\n",
    "    numFeat = len(open(fileName).readline().split('\\t'))\n",
    "    dataMat = [];labelMat = []\n",
    "    fr = open(fileName)\n",
    "    for line in fr.readlines():\n",
    "        lineArr = []\n",
    "        curLine = line.strip().split('\\t')\n",
    "        for i in range(numFeat - 1):\n",
    "            lineArr.append(float(curLine[i]))\n",
    "        dataMat.append(lineArr)\n",
    "        labelMat.append(float(curLine[-1]))\n",
    "    return dataMat,labelMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n",
      "total error:  0.40468227424749165 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "datArr,labelArr = loadDataSet('horseColicTraining.txt')\n",
    "classifierArray = adaBoostTrainDS(datArr,labelArr,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]\n",
      " [0.1929965]]\n",
      "[[0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]\n",
      " [0.28949475]]\n",
      "[[0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]\n",
      " [0.33774388]]\n",
      "[[0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]\n",
      " [0.36186844]]\n",
      "[[0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]\n",
      " [0.37393072]]\n",
      "[[0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]\n",
      " [0.37996186]]\n",
      "[[0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]\n",
      " [0.38297743]]\n",
      "[[0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]\n",
      " [0.38448522]]\n",
      "[[0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]\n",
      " [0.38523911]]\n",
      "[[0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]\n",
      " [0.38561606]]\n"
     ]
    }
   ],
   "source": [
    "testArr,testLabelArr = loadDataSet('horseColicTest.txt')\n",
    "prediction10 = adaClassify(testArr,classifierArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errArr = np.mat(np.ones((67,1)))\n",
    "errArr[prediction10 != np.mat(testLabelArr).T].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
